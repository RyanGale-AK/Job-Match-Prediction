#bestlam
lasso.mod=glmnet(X_train,Ytrain1,alpha=1,lambda=bestlam)
coef(lasso.mod)[,1]
pred.lasso = predict(lasso.mod, s = bestlam, newx = X_te)
mean((Y_te1-pred.lasso)^2)
lasso_mseA = rep(0,50)
lasso_mseA[1] = mean((Y_te1-pred.lasso)^2)
B = rep(0.5,50)
Ytrain2 = X_train%*%B + eps_train
Y_te2 = X_te%*%B + eps_te
#alpha=0 is the ridge penalty, alpha=1 is the lasso penalty
cv.out=cv.glmnet(X_train,Ytrain2,alpha=0,lambda=grid) #10 fold cross validation
bestlam=cv.out$lambda.min
#bestlam
ridge.mod=glmnet(X_train,Ytrain2,alpha=0,lambda=bestlam)
coef(ridge.mod)[,1]
pred.ridge = predict(ridge.mod, s = bestlam, newx = X_te)
mean((Y_te2-pred.ridge)^2)
ridge_mseB = rep(0,50)
ridge_mseB[1] = mean((Y_te2-pred.ridge)^2)
cv.out=cv.glmnet(X_train,Ytrain2,alpha=1,lambda=grid) #10 fold cross validation
bestlam=cv.out$lambda.min
#bestlam
lasso.mod=glmnet(X_train,Ytrain2,alpha=1,lambda=bestlam)
coef(lasso.mod)[,1]
pred.lasso = predict(lasso.mod, s = bestlam, newx = X_te)
mean((Y_te2-pred.lasso)^2)
lasso_mseB = rep(0,50)
lasso_mseB[1] = mean((Y_te2-pred.lasso)^2)
for(i in 2:50){
set.seed(i)
X_train = array(rnorm(p*N),c(N,p))
eps_train = rnorm(N)
Nte = 10^3
X_te = array(rnorm(p*Nte),c(Nte,p))
eps_te = rnorm(Nte)
Ytrain1 = X_train%*%A + eps_train
Y_te1 = X_te%*%A + eps_te
#alpha=0 is the ridge penalty, alpha=1 is the lasso penalty
cv.out=cv.glmnet(X_train,Ytrain1,alpha=0,lambda=grid) #10 fold cross validation
bestlam=cv.out$lambda.min
#bestlam
ridge.mod=glmnet(X_train,Ytrain1,alpha=0,lambda=bestlam)
coef(ridge.mod)[,1]
pred.ridge = predict(ridge.mod, s = bestlam, newx = X_te)
ridge_mseA[i] = mean((Y_te1-pred.ridge)^2)
}
for(i in 2:50){
set.seed(i)
X_train = array(rnorm(p*N),c(N,p))
eps_train = rnorm(N)
Nte = 10^3
X_te = array(rnorm(p*Nte),c(Nte,p))
eps_te = rnorm(Nte)
Ytrain1 = X_train%*%A + eps_train
Y_te1 = X_te%*%A + eps_te
cv.out=cv.glmnet(X_train,Ytrain1,alpha=1,lambda=grid) #10 fold cross validation
bestlam=cv.out$lambda.min
#bestlam
lasso.mod=glmnet(X_train,Ytrain1,alpha=1,lambda=bestlam)
coef(lasso.mod)[,1]
pred.lasso = predict(lasso.mod, s = bestlam, newx = X_te)
mean((Y_te1-pred.lasso)^2)
lasso_mseA[i] = mean((Y_te1-pred.lasso)^2)
}
for(i in 2:50){
set.seed(i)
X_train = array(rnorm(p*N),c(N,p))
eps_train = rnorm(N)
Nte = 10^3
X_te = array(rnorm(p*Nte),c(Nte,p))
eps_te = rnorm(Nte)
Ytrain2 = X_train%*%B + eps_train
Y_te2 = X_te%*%B + eps_te
#alpha=0 is the ridge penalty, alpha=1 is the lasso penalty
cv.out=cv.glmnet(X_train,Ytrain2,alpha=0,lambda=grid) #10 fold cross validation
bestlam=cv.out$lambda.min
#bestlam
ridge.mod=glmnet(X_train,Ytrain2,alpha=0,lambda=bestlam)
coef(ridge.mod)[,1]
pred.ridge = predict(ridge.mod, s = bestlam, newx = X_te)
ridge_mseB[i] = mean((Y_te2-pred.ridge)^2)
}
for(i in 2:50){
set.seed(i)
X_train = array(rnorm(p*N),c(N,p))
eps_train = rnorm(N)
Nte = 10^3
X_te = array(rnorm(p*Nte),c(Nte,p))
eps_te = rnorm(Nte)
Ytrain2 = X_train%*%B + eps_train
Y_te2 = X_te%*%B + eps_te
cv.out=cv.glmnet(X_train,Ytrain2,alpha=1,lambda=grid) #10 fold cross validation
bestlam=cv.out$lambda.min
#bestlam
lasso.mod=glmnet(X_train,Ytrain2,alpha=1,lambda=bestlam)
coef(lasso.mod)[,1]
pred.lasso = predict(lasso.mod, s = bestlam, newx = X_te)
mean((Y_te2-pred.lasso)^2)
lasso_mseB[i] = mean((Y_te2-pred.lasso)^2)
}
boxplot(ridge_mseA,lasso_mseA)
boxplot(ridge_mseB,lasso_mseB)
X = [[4,1,1,1],[1,1,0,0],[1,0,1,0],[1,0,0,1]]
X = ((4,1,1,1),(1,1,0,0),(1,0,1,0),(1,0,0,1))
X = rbind(c(4,1,1,1),c(1,1,0,0),c(1,0,1,0),c(1,0,0,1))
X = rbind(c(4,1,1,1),c(1,1,0,0),c(1,0,1,0),c(1,0,0,1))
Y = solve(X)
Y
choose(5,2)
1-choose(1024-2,32)/choose(1024,32)
1-choose(1024-3,32)/choose(1024,32)
1-choose(1024-1,32)/choose(1024,32)
1-choose(1024-5,32)/choose(1024,32)
1-choose(1024-6,32)/choose(1024,32)
1-choose(1024-7,32)/choose(1024,32)
1-choose(1024-20,32)/choose(1024,32)
2(1/0.06155303) + 3(1/0.09093689) + 3(1/0.09093689) + 20(1/0.1998094) + 7(1/0.4732545) + 1(1/0.03125) + 6(1/0.1738397) + 5(1/0.1470544)+ 5(1/0.1470544) + 2(1/0.06155303) + 3(1/0.09093689)
2(1/0.06155303) + 3(1/0.09093689) + 3(1/0.09093689) + 20(1/0.1998094) + 7(1/0.4732545) + 1(1/0.03125) + 6(1/0.1738397) + 5(1/0.1470544)+ 5(1/0.1470544) + 2(1/0.06155303) + 3(1/0.09093689)
2*(1/0.06155303) + 3*(1/0.09093689) + 3*(1/0.09093689) + 20*(1/0.1998094) + 7*(1/0.4732545) + 1*(1/0.03125) + 6*(1/0.1738397) + 5*(1/0.1470544)+ 5*(1/0.1470544) + 2*(1/0.06155303) + 3*(1/0.09093689)
setwd("~/Downloads/")
Nutr = read.csv("NutritionStdy.csv")
View(Nutr)
setwd("~/Downloads/")
Nutr = read.csv("NutritionStdy.csv")
Nutr$Vitamin = as.factor(Nutr$Vitamin)
setwd("~/Downloads/")
Nutr = read.csv("NutritionStdy.csv")
Nutr$Vitamin = as.factor(Nutr$Vitamin)
lm(BetaPlasma~. ,data = Nutr)
View(Nutr)
setwd("~/Downloads/")
Nutr = read.csv("NutritionStdy.csv")
Nutr$Vitamin = as.factor(Nutr$Vitamin)
L1 = lm(BetaPlasma~. ,data = Nutr)
model.matrix(L1)
setwd("~/Downloads/")
Nutr = read.csv("NutritionStdy.csv")
Nutr$Vitamin = as.factor(Nutr$Vitamin)
L1 = lm(BetaPlasma~. ,data = Nutr)
L1
model.matrix(L1)
setwd("~/Downloads/")
Nutr = read.csv("NutritionStdy.csv")
Nutr$Vitamin = as.factor(Nutr$Vitamin)
a.lm = lm(BetaPlasma~. ,data = Nutr)
a.lm
M = model.matrix(a.lm)
M
#test vitamin2 coef = 0
Li = c(0,0,1,0,0,0,0)
Li%*%M
#test vitamin2 coef = 0
Li = c(0,0,1,0,0,0,0)
Li%*%M
View(M)
#test vitamin2 coef = 0
Li = c(0,0,1,0,0,0,0)
M%*%t(Li)
t(Li)
Li
#test vitamin2 coef = 0
Li = c(0,0,1,0,0,0,0)
Li%*%M
#test vitamin2 coef = 0
Li = c(0,0,1,0,0,0,0)
M%*%Li
#vitamin3 coef = vitamin2 coef /2
#Lii =
#test vitamin2 coef = 0
Li = c(0,0,1,0,0,0,0)
M%*%Li
#vitamin3 coef = vitamin2 coef /2
Lii = c(0,0,-1/2,1,0,0,0)
M%*%Lii
#test vitamin2 coef = 0
Li = c(0,0,1,0,0,0,0)
Li%*%coef(a.lm)
#vitamin3 coef = vitamin2 coef /2
Lii = c(0,0,-1/2,1,0,0,0)
M%*%Lii
#test vitamin2 coef = 0
Li = c(0,0,1,0,0,0,0)
Li%*%coef(a.lm)
#vitamin3 coef = vitamin2 coef /2
Lii = c(0,0,-1/2,1,0,0,0)
Lii%*%coef(a.lm)
setwd("~/Downloads/")
Nutr = read.csv("NutritionStdy.csv")
Nutr$Vitamin = as.factor(Nutr$Vitamin)
a.lm = lm(BetaPlasma~ . ,data = log(Nutr))
setwd("~/Downloads/")
Nutr = read.csv("NutritionStdy.csv")
Nutr$Vitamin = as.factor(Nutr$Vitamin)
a.lm = lm(log(BetaPlasma)~ .,data = Nutr)
a.lm
M = model.matrix(a.lm)
M
#test vitamin2 coef = 0
Li = c(0,0,1,0,0,0,0)
Li%*%coef(a.lm)
#vitamin3 coef = vitamin2 coef /2
Lii = c(0,0,-1/2,1,0,0,0)
Lii%*%coef(a.lm)
Li%*%coef(a.lm)
Lii%*%coef(a.lm)
#test vitamin2 coef = 0
Li = c(0,0,1,0,0,0,0)
#vitamin3 coef = vitamin2 coef /2
Lii = c(0,0,-1/2,1,0,0,0)
Li%*%coef(a.lm)
Lii%*%coef(a.lm)
contrasts = list(Vitamin = "contr.helmert")
View(contrasts)
View(contrasts)
Li%*%coef(a.lm)
Lii%*%coef(a.lm)
b.lm = lm(log(BetaPlasma)~ .,data = Nutr, contrasts = list(Vitamin = "contr.helmert"))
Li%*%coef(a.lm)
Lii%*%coef(a.lm)
lm(log(BetaPlasma)~ .,data = Nutr, contrasts = list(Vitamin = "contr.helmert"))
Li%*%coef(a.lm)
Lii%*%coef(a.lm)
b.lm = lm(log(BetaPlasma)~ .,data = Nutr, contrasts = list(Vitamin = "contr.helmert"))
Li%*%coef(b.lm)
Lii%*%coef(b.lm)
Li%*%coef(a.lm)
Lii%*%coef(a.lm)
b.lm = lm(log(BetaPlasma)~ .,data = Nutr, contrasts = list(Vitamin = "contr.helmert"))
coef(b.lm)
L= rbind(c(0,0,1,0,0,0,0),c(0,0,-1/2,1,0,0,0))
View(L)
L= rbind(c(0,0,1,0,0,0,0),c(0,0,-1/2,1,0,0,0))
B= coef(a.lm)
Anova(a.lm)
anova(a.lm)
L= rbind(c(0,0,1,0,0,0,0),c(0,0,-1/2,1,0,0,0))
B= coef(a.lm)
variance = L%*%solve()
anova(a.lm)
L= rbind(c(0,0,1,0,0,0,0),c(0,0,-1/2,1,0,0,0))
B= coef(a.lm)
X=Nur[,2:7]
anova(a.lm)
L= rbind(c(0,0,1,0,0,0,0),c(0,0,-1/2,1,0,0,0))
B= coef(a.lm)
X=Nutr[,2:7]
View(Nutr)
View(Nutr)
View(Nutr)
setwd("~/Downloads/")
Nutr = read.csv("NutritionStdy.csv")
Nutr$Vitamin = as.factor(Nutr$Vitamin)
a.lm = lm(log(BetaPlasma)~ .,data = Nutr)
a.lm
M = model.matrix(a.lm)
M
anova(a.lm)
L= rbind(c(0,0,1,0,0,0,0),c(0,0,-1/2,1,0,0,0))
B= coef(a.lm)
X=model.matrix(a.lm)
variance = L%*%solve(t(X)%*%X)%*%t(L)
MSE = 140.207/307
(t(L%*%B)%*%solve(variance)%*%LB)/MSE
anova(a.lm)
L= rbind(c(0,0,1,0,0,0,0),c(0,0,-1/2,1,0,0,0))
B= coef(a.lm)
X=model.matrix(a.lm)
variance = L%*%solve(t(X)%*%X)%*%t(L)
MSE = 140.207/307
(t(L%*%B)%*%solve(variance)%*%L%*%B)/MSE
anova(a.lm)
L= rbind(c(0,0,1,0,0,0,0),c(0,0,-1/2,1,0,0,0))
B= coef(a.lm)
X=model.matrix(a.lm)
variance = L%*%solve(t(X)%*%X)%*%t(L)
MSE = 140.207/307
(t(L%*%B)%*%solve(variance)%*%L%*%B)/MSE
anova(a.lm)
L= rbind(c(0,0,1,0,0,0,0),c(0,0,-1/2,1,0,0,0))
B= coef(a.lm)
X=model.matrix(a.lm)
variance = L%*%solve(t(X)%*%X)%*%t(L)
MSE = 140.207/307
F = (t(L%*%B)%*%solve(variance)%*%L%*%B)/MSE
F/2
Anova(a.lm)
library(car)
Anova(a.lm)
L= rbind(c(0,0,1,0,0,0,0),c(0,0,-1/2,1,0,0,0))
B= coef(a.lm)
X=model.matrix(a.lm)
variance = L%*%solve(t(X)%*%X)%*%t(L)
MSE = 140.207/307
F = (t(L%*%B)%*%solve(variance)%*%L%*%B)/MSE
F/2
L%*%B
Anova(a.lm)
Anova(b.lm)
Li%*%coef(a.lm)
#test vitamin2 coef = 0
Li = c(0,0,1,0,0,0,0)
#vitamin3 coef = vitamin2 coef /2
Lii = c(0,0,-1/2,1,0,0,0)
Li%*%coef(a.lm)
Lii%*%coef(a.lm)
b.lm = lm(log(BetaPlasma)~ .,data = Nutr, contrasts = list(Vitamin = "contr.helmert"))
coef(b.lm)
Anova(a.lm)
Anova(b.lm)
L= rbind(c(0,0,1,0,0,0,0),c(0,0,-1/2,1,0,0,0))
B= coef(a.lm)
X=model.matrix(a.lm)
variance = L%*%solve(t(X)%*%X)%*%t(L)
MSE = 140.207/307
F = (t(L%*%B)%*%solve(variance)%*%L%*%B)/MSE
F/2
setwd("~/Downloads/")
Nutr = read.csv("NutritionStdy.csv")
Nutr$Vitamin = as.factor(Nutr$Vitamin)
a.lm = lm(log(BetaPlasma)~ .,data = Nutr)
a.lm
M = model.matrix(a.lm)
M
#test vitamin2 coef = 0
Li = c(0,0,1,0,0,0,0)
#vitamin3 coef = vitamin2 coef /2
Lii = c(0,0,-1/2,1,0,0,0)
Li%*%coef(a.lm)
Lii%*%coef(a.lm)
b.lm = lm(log(BetaPlasma)~ .,data = Nutr, contrasts = list(Vitamin = "contr.helmert"))
coef(b.lm)
library(car)
Anova(a.lm)
Anova(b.lm)
L= rbind(c(0,0,1,0,0,0,0),c(0,0,-1/2,1,0,0,0))
B= coef(a.lm)
X=model.matrix(a.lm)
variance = L%*%solve(t(X)%*%X)%*%t(L)
MSE = 140.207/307
F = (t(L%*%B)%*%solve(variance)%*%L%*%B)/MSE
F/2
#test vitamin2 coef = 0
Li = c(0,0,1,0,0,0,0)
Li
#vitamin3 coef = vitamin2 coef /2
Lii = c(0,0,-1/2,1,0,0,0)
Lii
source('~/Documents/Git/Job-Match-Prediction/Tree.R')
job.test
Y[train]
source('~/Documents/Git/Job-Match-Prediction/Tree.R')
source('~/Documents/Git/Job-Match-Prediction/Tree.R')
source('~/Documents/Git/Job-Match-Prediction/Tree.R')
source('~/Documents/Git/Job-Match-Prediction/Tree.R')
mean(cv.error)
###Tree method code
library(tree)
library(randomForest)
setwd("~/Documents/Git/Job-Match-Prediction")
>>>>>>> 84fa75361c3cea7561078cba140fc1010675cc23
job_data = read.csv("dtm_jobs.csv", header =TRUE)
set.seed(1)
#Randomly shuffle the data
shuffledData<-job_data[sample(nrow(job_data)),]
#Create 10 equally size folds
<<<<<<< HEAD
folds <- cut(seq(1,nrow(shuffledData)),breaks=5,labels=FALSE)
A = shuffledData[,11:1814]
X= as.matrix(A)
A = job_data[,11:1814]
X= as.matrix(A)
Y = as.vector(shuffledData$Category)
library(tree)
data = data.frame(X,Y)
train = sample(nrow(data), (nrow(data))/2)
job.test = data[-train,]
library(gbm)
set.seed(1)
boost.job = gbm(Y~X, data = data[train,], distribution = "gaussian", n.trees = 500,
interaction.depth = 4)
boost.job = gbm(Y~X, data = data[-train,], distribution = "gaussian", n.trees = 500,
interaction.depth = 4)
source('C:/Users/Jeffrey Wu/Desktop/GitHub/Job-Match-Prediction/Tree.R')
source('C:/Users/Jeffrey Wu/Desktop/GitHub/Job-Match-Prediction/Tree.R')
###Tree method code
#setwd("~/Documents/Git/Job-Match-Prediction")
job_data = read.csv("dtm_jobs.csv", header =TRUE)
set.seed(1)
#Randomly shuffle the data
shuffledData<-job_data[sample(nrow(job_data)),]
#Create 10 equally size folds
folds <- cut(seq(1,nrow(shuffledData)),breaks=5,labels=FALSE)
A = shuffledData[,11:1814]
X= as.matrix(A)
Y = as.vector(shuffledData$Cat1)
library(tree)
data = data.frame(Y,X)
setwd("~/Documents/Git/Job-Match-Prediction")
job_data = read.csv("dtm_jobs.csv", header =TRUE)
set.seed(1)
#Randomly shuffle the data
#shuffledData<-job_data[sample(nrow(job_data)),]
#Create 10 equally size folds
#folds <- cut(seq(1,nrow(shuffledData)),breaks=5,labels=FALSE)
#X = shuffledData[,11:1814]
X = job_data[,11:1814]
Y = as.vector(job_data$Category)
Y = as.factor(Y)
data = data.frame(Y,X)
# tree.job = tree(Y~X, data = data)
# summary(tree.job)
# plot(tree.job)
#
# cv.tree.job = cv.tree(tree.job)
# prune.job = prune.tree(tree.job,best=5)
train = sample(nrow(data), (nrow(data))*.75)
job.test = Y[-train]
library(randomForest)
bag.job = randomForest(x=X, y=Y, subset = train, importance = TRUE, ntree=50)
source('C:/Users/Jeffrey Wu/Desktop/GitHub/Job-Match-Prediction/Tree.R')
error
source('C:/Users/Jeffrey Wu/Desktop/Research Project Materials/Lasso Quantile Regression Code.R')
lasso.mod = rq(y.net ~ ., data = barro, method = "lasso", lambda = bestlam, tau = 0.75)
lasso.coef=coef(lasso.mod)
lasso.coef[lasso.coef!=0]
###Quantile regression done with lasso
data(barro)
=======
X = shuffledData[,11:1814]
source('~/Documents/Git/Job-Match-Prediction/Tree.R')
mean(cv.error)
job_data_v2 = read.csv("dtm_jobs_v2.csv", header =TRUE)
source('~/Documents/Git/Job-Match-Prediction/Tree.R')
mean(cv.error)
Y = as.vector(shuffledData$Cat1)
source('~/Documents/Git/Job-Match-Prediction/Tree.R')
mean(cv.error)
source('~/Documents/Git/Job-Match-Prediction/lasso.R')
job_data = read.csv("dtm_jobs_v2.csv", header =TRUE)
source('~/Documents/Git/Job-Match-Prediction/lasso.R')
source('~/Documents/Git/Job-Match-Prediction/lasso.R')
source('~/Documents/Git/Job-Match-Prediction/Tree.R')
source('~/Documents/Git/Job-Match-Prediction/Tree.R')
importance(rf.job, type =1)
import = importance(rf.job, type =1, class=1)
import = importance(rf.job, type =1, class="Admin")
View(import)
import = importance(rf.job, type =1, class="Business")
import = importance(rf.job, type =1, class="Tech")
import = importance(rf.job, type =1, class="Sales")
import = importance(rf.job, type =2, class="Sales")
import = importance(rf.job, type =1, class="Sales")
source('~/Documents/Git/Job-Match-Prediction/Tree.R')
source('~/Documents/Git/Job-Match-Prediction/lasso.R')
source('~/Documents/Git/Job-Match-Prediction/lasso.R')
coef(lasso.mod)
coef(lasso.mod)[!=0]
lasso.coef = coef(lasso.mod)
lasso.coef[lasso.coef!=0]
lasso.coef[!=0]
print(i in lasso.coef[i]!=0)
lasso.coef = coef(lasso.mod)
lasso.coef[lasso.coef != 0]
a = 0
for (i in length(lasso.coef)){
if (lass.coef != 0){
a = c(a,lasso.coef[i])
}
}
mean_error = mean(cv.error)
lasso.coef = coef(lasso.mod)
a = 0
for (i in length(lasso.coef)){
if (lass.coef != 0){
a = c(a,lasso.coef[i])
}
}
lasso.coef = coef(lasso.mod)
lasso.mod$beta
lasso.coef = lasso.mod$beta
View(lasso.coef)
View(lasso.coef)
lasso.coef = coef(lasso.mod)
lasso.coef = [which(lasso.coef!=0)]
lasso.coef = lasso.coef[which(lasso.coef!=0)]
lasso.coef = coef(lasso.mod,s=bestlam)
lasso.coef = lasso.coef[which(lasso.coef!=0)]
lasso.coef[1]
lasso.coef = coef(lasso.mod,s=bestlam)[1]
lasso.coef = lasso.coef[which(lasso.coef!=0)]
install.packages("glmnetcr")
library("glmnetcr")
nonzero.glmnet.cr(lasso.mod)
library("glmnetcr")
nonzero.glmnet.cr(lasso.mod)
library("glmnet")
nonzero.glmnet.cr(lasso.mod)
install.packages("coefplot")
library("coefplot")
extract.coef(lasso.mod)
extract.coef(lasso.mod, s=bestlam)
View(lasso.coef)
lasso.coef = coef(lasso.mod,s=bestlam)
View(lasso.coef)
lasso.coef
lasso.coef$Admin
admin = lasso.coef$Admin
View(admin)
admin[which(admin!=0)]
admin[admin!=0]
>>>>>>> 84fa75361c3cea7561078cba140fc1010675cc23
